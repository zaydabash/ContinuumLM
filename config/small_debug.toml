# Small debug configuration for quick testing
# This config uses a tiny model that can train quickly on CPU

[model]
d_model = 64
n_heads = 2
d_ff = 256
vocab_size = 1000
max_seq_len = 32
is_neural_ode = true
ode_t0 = 0.0
ode_t1 = 1.0
ode_solver = "Tsit5"
ode_sensealg = "InterpolatingAdjoint"
ode_atol = 1e-6
ode_rtol = 1e-6
ode_integrator = "generic"
ode_nsteps = 4
reversible = false
n_layers = 2

[training]
batch_size = 4
seq_len = 32
num_steps = 1000
log_every = 50
eval_every = 200
lr = 1e-3
weight_decay = 0.01
grad_clip = 1.0
warmup_steps = 100
device = "cpu"
checkpoint_dir = "checkpoints"
checkpoint_every = 500
save_best = true
seed = 42
log_dir = "logs"
run_name = "small_debug"

[data]
corpus_path = "data/corpus.txt"
tokenizer_path = "data/tokenizer.json"
vocab_size = 1000
train_split = 0.9
